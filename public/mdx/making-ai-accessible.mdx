## Making AI accessible

by Andrej Karpathy

Transcripts from [AI Ascent 2024](https://youtube.com/watch?v=c3b-JASoPi0):

Everyone is trying to build what I refer to as LLM OS. I like to think of it as an operating system. You have to get peripherals that you plug into this new CPU. The peripherals are text, images, audio, and all the modalities.

You have a CPU, which is the LLM transformer itself, connected to all the software 1.0 infrastructure that we've already built. Everyone is trying to build something like that and make it available as something customizable to all the different nooks and crannies of the economy. That's roughly what everyone's trying to build out and what we heard about earlier today. It's headed towards bringing up and down relatively self-contained agents that we can give high-level tasks to and specialize in various ways. It's gonna be very interesting and exciting.

It's not just one agent. It's many agents.

---

OpenAI is trying to build out this LLM OS. As we heard earlier today, it's trying to develop this platform on top of which you can position different companies in different verticals. The OS analogy is interesting because when you look at something like Windows, these are operating systems. They come with a few default apps.

A browser comes with Windows. You can use the Edge browser. In the same way, OpenAI or any of the other companies might come up with a few default apps, but that doesn't mean you can't have different browsers running on it just like you can have different chat agents running on that infrastructure. There will be a few default apps, but there will also potentially be a vibrant ecosystem of all kinds of apps fine-tuned to all the different nooks and crannies of the economy.

I really like the analogy of the early iPhone apps and what they looked like. They were all kind of jokes. It took time for that to develop. We're going through the same thing right now. People are trying to figure out what this thing is good at, what it's not good at, how to work it, how to program with it, how to debug it, how to get it to perform real tasks, and what kind of oversight is needed because it's quite autonomous, but not fully autonomous.

There's many things to think through and understand the psychology of it. That's what's gonna take some time to figure out exactly how to work with this infrastructure. We'll see that over the next few years.
